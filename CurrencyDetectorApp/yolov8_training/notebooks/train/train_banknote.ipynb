{
 "cells": [
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "end_time": "2026-01-20T18:12:20.778249800Z",
     "start_time": "2026-01-20T18:12:14.438785600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "# ==================== –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–à–ê ====================\n",
    "CURRENT_DIR = os.getcwd()\n",
    "BASE_DIR = os.path.abspath(os.path.join(CURRENT_DIR, \"..\", \"..\"))\n",
    "DATA_YAML = os.path.join(BASE_DIR, \"datasets\", \"coin\", \"data.yaml\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ü™ô –ú–ê–ö–ï–î–û–ù–°–ö–ò –î–ï–¢–ï–ö–¢–û–† –ó–ê –ú–û–ù–ï–¢–ò - –û–ø—Ç–∏–º–∏–∑–∏—Ä–∞–Ω–∞ –≤–µ—Ä–∑–∏—ò–∞\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"üìÅ BASE_DIR: {BASE_DIR}\")\n",
    "print(f\"üìÑ DATA_YAML: {DATA_YAML}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "\n",
    "# ==================== –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–à–ê –ó–ê –¢–†–ï–ù–ò–†–ê–ä–ï ====================\n",
    "class CoinDetectorConfig:\n",
    "    \"\"\"–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—ò–∞ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–∞–Ω–∞ –∑–∞ –º–∞–ª –¥–∞—Ç–∞—Å–µ—Ç (70 —Å–ª–∏–∫–∏ –ø–æ –∫–ª–∞—Å–∞)\"\"\"\n",
    "\n",
    "    # –û—Å–Ω–æ–≤–Ω–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏\n",
    "    TRAIN_NEW = True\n",
    "    MODEL_SIZE = 'yolov8m.pt'  # Medium –º–æ–¥–µ–ª - –ø–æ–¥–æ–±–∞—Ä –æ–¥ 's' –∑–∞ precision\n",
    "\n",
    "    # –¢—Ä–µ–Ω–∏—Ä–∞—ö–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏\n",
    "    EPOCHS = 200  # –ü–æ–≤–µ—ú–µ –µ–ø–æ—Ö–∏ –∑–∞ –º–∞–ª –¥–∞—Ç–∞—Å–µ—Ç\n",
    "    BATCH_SIZE = 8  # –ü–æ–º–∞–ª batch –∑–∞ –ø–æ–¥–æ–±—Ä–∞ –≥–µ–Ω–µ—Ä–∞–ª–∏–∑–∞—Ü–∏—ò–∞\n",
    "    IMAGE_SIZE = 640\n",
    "    PATIENCE = 50  # –î–æ–ª–≥–æ —Ç—Ä–ø–µ–Ω–∏–µ –∑–∞ –º–∞–ª –¥–∞—Ç–∞—Å–µ—Ç\n",
    "\n",
    "    # Optimizer\n",
    "    OPTIMIZER = \"AdamW\"\n",
    "    LR0 = 0.0005  # –ü–æ–º–∞–ª–∞ learning rate –∑–∞ fine-tuning\n",
    "    LRF = 0.001\n",
    "    MOMENTUM = 0.937\n",
    "    WEIGHT_DECAY = 0.001  # –ü–æ–≤–∏—Å–æ–∫ –∑–∞ –¥–∞ —Å–µ —Å–ø—Ä–µ—á–∏ overfitting\n",
    "    WARMUP_EPOCHS = 5.0\n",
    "\n",
    "    # –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—ò–∞ (AGGRESSIVE –∑–∞ –º–∞–ª –¥–∞—Ç–∞—Å–µ—Ç)\n",
    "    HSV_H = 0.02  # –í–∞—Ä–∏—ò–∞—Ü–∏—ò–∞ –Ω–∞ –±–æ—ò–∞\n",
    "    HSV_S = 0.8\n",
    "    HSV_V = 0.5\n",
    "    DEGREES = 45  # –ó–≥–æ–ª–µ–º–µ–Ω–∞ —Ä–æ—Ç–∞—Ü–∏—ò–∞\n",
    "    TRANSLATE = 0.2\n",
    "    SCALE = 0.7\n",
    "    SHEAR = 5.0\n",
    "    PERSPECTIVE = 0.001\n",
    "    FLIPUD = 0.5\n",
    "    FLIPLR = 0.5\n",
    "    MOSAIC = 1.0\n",
    "    MIXUP = 0.15  # –î–æ–¥–∞–¥–µ–Ω–æ mixup –∑–∞ –ø–æ–¥–æ–±—Ä–∞ –≥–µ–Ω–µ—Ä–∞–ª–∏–∑–∞—Ü–∏—ò–∞\n",
    "    COPY_PASTE = 0.3  # Copy-paste –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—ò–∞\n",
    "\n",
    "    # Loss weights (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–∞–Ω–æ –∑–∞ –º–æ–Ω–µ—Ç–∏)\n",
    "    BOX = 7.5\n",
    "    CLS = 1.0  # –ó–≥–æ–ª–µ–º–µ–Ω–æ –∑–∞ –ø–æ–¥–æ–±—Ä–∞ –∫–ª–∞—Å–∏—Ñ–∏–∫–∞—Ü–∏—ò–∞\n",
    "    DFL = 1.5\n",
    "\n",
    "    # Inference\n",
    "    CONF_THRESHOLD = 0.35  # –ü–æ–Ω–∏–∫–æ–∫ threshold –∑–∞ –ø–æ–¥–æ–±—Ä–∞ recall\n",
    "    IOU_THRESHOLD = 0.5\n",
    "\n",
    "    # Output\n",
    "    MODEL_NAME = 'coin_detector_mk_optimized'\n",
    "    SAVE_PERIOD = 20\n",
    "\n",
    "    @classmethod\n",
    "    def get_model_path(cls):\n",
    "        return os.path.join(BASE_DIR, \"models\", cls.MODEL_NAME, \"weights\", \"best.pt\")\n",
    "\n",
    "\n",
    "# ==================== –§–£–ù–ö–¶–ò–ò –ó–ê –û–ë–†–ê–ë–û–¢–ö–ê –ù–ê –°–õ–ò–ö–ò ====================\n",
    "def remove_background_grabcut(image, bbox, padding=5):\n",
    "    \"\"\"\n",
    "    GrabCut –º–µ—Ç–æ–¥ - –æ–¥–ª–∏—á–µ–Ω –∑–∞ –º–æ–Ω–µ—Ç–∏ —Å–æ –∫–æ–º–ø–ª–µ–∫—Å–Ω–∞ –ø–æ–∑–∞–¥–∏–Ω–∞\n",
    "\n",
    "    Args:\n",
    "        image: –í–ª–µ–∑–Ω–∞ —Å–ª–∏–∫–∞\n",
    "        bbox: Bounding box [x1, y1, x2, y2]\n",
    "        padding: Padding –æ–∫–æ–ª—É bbox\n",
    "    \"\"\"\n",
    "    x1, y1, x2, y2 = map(int, bbox)\n",
    "    h, w = image.shape[:2]\n",
    "\n",
    "    # –î–æ–¥–∞—ò padding\n",
    "    x1 = max(0, x1 - padding)\n",
    "    y1 = max(0, y1 - padding)\n",
    "    x2 = min(w, x2 + padding)\n",
    "    y2 = min(h, y2 + padding)\n",
    "\n",
    "    cropped = image[y1:y2, x1:x2].copy()\n",
    "\n",
    "    if cropped.size == 0 or cropped.shape[0] < 10 or cropped.shape[1] < 10:\n",
    "        return np.zeros((1, 1, 4), dtype=np.uint8)\n",
    "\n",
    "    # GrabCut rectangle (–≤–Ω–∞—Ç—Ä–µ—à–µ–Ω, –ø–æ–º–∞–ª –æ–¥ —Ü–µ–ª–∏–æ—Ç crop)\n",
    "    ch, cw = cropped.shape[:2]\n",
    "    rect = (int(cw*0.1), int(ch*0.1), int(cw*0.8), int(ch*0.8))\n",
    "\n",
    "    # –ò–Ω–∏—Üij–∞–ª–∏–∑–∏—Ä–∞—ò –º–∞—Å–∫–∏\n",
    "    mask = np.zeros(cropped.shape[:2], np.uint8)\n",
    "    bgd_model = np.zeros((1, 65), np.float64)\n",
    "    fgd_model = np.zeros((1, 65), np.float64)\n",
    "\n",
    "    try:\n",
    "        # GrabCut –∞–ª–≥–æ—Ä–∏—Ç–∞–º\n",
    "        cv2.grabCut(cropped, mask, rect, bgd_model, fgd_model, 5, cv2.GC_INIT_WITH_RECT)\n",
    "\n",
    "        # –ú–∞—Å–∫–∞ –∑–∞ foreground\n",
    "        mask2 = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')\n",
    "\n",
    "        # –ú–æ—Ä—Ñ–æ–ª–æ—à–∫–∏ –æ–ø–µ—Ä–∞—Ü–∏–∏\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "        mask2 = cv2.morphologyEx(mask2, cv2.MORPH_CLOSE, kernel)\n",
    "        mask2 = cv2.morphologyEx(mask2, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "        # Gaussian blur –∑–∞ smooth edges\n",
    "        mask2 = (mask2 * 255).astype(np.uint8)\n",
    "        mask2 = cv2.GaussianBlur(mask2, (7, 7), 0)\n",
    "\n",
    "    except:\n",
    "        # Fallback –∞–∫–æ GrabCut –Ω–µ —É—Å–ø–µ–µ\n",
    "        mask2 = np.ones(cropped.shape[:2], dtype=np.uint8) * 255\n",
    "\n",
    "    # –ö—Ä–µ–∏—Ä–∞—ò BGRA\n",
    "    bgra = cv2.cvtColor(cropped, cv2.COLOR_BGR2BGRA)\n",
    "    bgra[:, :, 3] = mask2\n",
    "\n",
    "    return bgra\n",
    "\n",
    "\n",
    "def remove_background_edge_detection(image, bbox, padding=10):\n",
    "    \"\"\"\n",
    "    Edge detection –º–µ—Ç–æ–¥ - –æ–¥–ª–∏—á–µ–Ω –∑–∞ –º–æ–Ω–µ—Ç–∏ —Å–æ –æ—Å—Ç–∞—Ä —Ä–∞–±\n",
    "\n",
    "    Args:\n",
    "        image: –í–ª–µ–∑–Ω–∞ —Å–ª–∏–∫–∞\n",
    "        bbox: Bounding box [x1, y1, x2, y2]\n",
    "        padding: Padding\n",
    "    \"\"\"\n",
    "    x1, y1, x2, y2 = map(int, bbox)\n",
    "    h, w = image.shape[:2]\n",
    "\n",
    "    x1 = max(0, x1 - padding)\n",
    "    y1 = max(0, y1 - padding)\n",
    "    x2 = min(w, x2 + padding)\n",
    "    y2 = min(h, y2 + padding)\n",
    "\n",
    "    cropped = image[y1:y2, x1:x2].copy()\n",
    "\n",
    "    if cropped.size == 0 or cropped.shape[0] == 0 or cropped.shape[1] == 0:\n",
    "        return np.zeros((1, 1, 4), dtype=np.uint8)\n",
    "\n",
    "    gray = cv2.cvtColor(cropped, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Bilateral filter - –∑–∞—á—É–≤–∞ —Ä–∞–±–æ–≤–∏\n",
    "    filtered = cv2.bilateralFilter(gray, 9, 75, 75)\n",
    "\n",
    "    # Canny edge detection\n",
    "    edges = cv2.Canny(filtered, 30, 100)\n",
    "\n",
    "    # Dilate –∑–∞ –¥–∞ —Å–µ –∑–∞—Ç–≤–æ—Ä–∞—Ç –ø—Ä–∞–∑–Ω–∏–Ω–∏—Ç–µ\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    edges = cv2.dilate(edges, kernel, iterations=2)\n",
    "\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    mask = np.zeros(cropped.shape[:2], dtype=np.uint8)\n",
    "\n",
    "    if contours:\n",
    "        # –ù–∞—ò–¥–∏ –Ω–∞—ò–≥–æ–ª–µ–º contour (–ø—Ä–µ—Ç–ø–æ—Å—Ç–∞–≤–∫–∞: —Ç–æ–∞ –µ –º–æ–Ω–µ—Ç–∞—Ç–∞)\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        cv2.drawContours(mask, [largest_contour], -1, 255, -1)\n",
    "    else:\n",
    "        # Fallback: —Ü–µ–ª–∞ —Å–ª–∏–∫–∞\n",
    "        mask = np.ones(cropped.shape[:2], dtype=np.uint8) * 255\n",
    "\n",
    "    # –ú–æ—Ä—Ñ–æ–ª–æ—à–∫–∏ –æ–ø–µ—Ä–∞—Ü–∏–∏\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7))\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "    mask = cv2.GaussianBlur(mask, (9, 9), 0)\n",
    "\n",
    "    bgra = cv2.cvtColor(cropped, cv2.COLOR_BGR2BGRA)\n",
    "    bgra[:, :, 3] = mask\n",
    "\n",
    "    return bgra\n",
    "\n",
    "\n",
    "def remove_background_hough_circles(image, bbox, padding=10):\n",
    "    \"\"\"\n",
    "    Hough Circles –º–µ—Ç–æ–¥ - –æ—Ä–∏–≥–∏–Ω–∞–ª–Ω–∏–æ—Ç, –ø–æ–¥–æ–±—Ä–µ–Ω\n",
    "\n",
    "    Args:\n",
    "        image: –í–ª–µ–∑–Ω–∞ —Å–ª–∏–∫–∞\n",
    "        bbox: Bounding box [x1, y1, x2, y2]\n",
    "        padding: Padding –æ–∫–æ–ª—É –º–æ–Ω–µ—Ç–∞—Ç–∞\n",
    "    \"\"\"\n",
    "    x1, y1, x2, y2 = map(int, bbox)\n",
    "    h, w = image.shape[:2]\n",
    "\n",
    "    x1 = max(0, x1 - padding)\n",
    "    y1 = max(0, y1 - padding)\n",
    "    x2 = min(w, x2 + padding)\n",
    "    y2 = min(h, y2 + padding)\n",
    "\n",
    "    cropped = image[y1:y2, x1:x2].copy()\n",
    "\n",
    "    if cropped.size == 0 or cropped.shape[0] == 0 or cropped.shape[1] == 0:\n",
    "        return np.zeros((1, 1, 4), dtype=np.uint8)\n",
    "\n",
    "    gray = cv2.cvtColor(cropped, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (9, 9), 0)\n",
    "\n",
    "    # Adaptive histogram equalization\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    enhanced = clahe.apply(blurred)\n",
    "\n",
    "    # Hough Circles —Å–æ –ø–æ–≤–µ—ú–µ attempts\n",
    "    circles = None\n",
    "    params = [\n",
    "        {'param1': 50, 'param2': 30, 'minR': 0.20, 'maxR': 0.70},\n",
    "        {'param1': 40, 'param2': 25, 'minR': 0.25, 'maxR': 0.65},\n",
    "        {'param1': 60, 'param2': 35, 'minR': 0.15, 'maxR': 0.75},\n",
    "    ]\n",
    "\n",
    "    for param in params:\n",
    "        circles = cv2.HoughCircles(\n",
    "            enhanced,\n",
    "            cv2.HOUGH_GRADIENT,\n",
    "            dp=1,\n",
    "            minDist=max(cropped.shape[:2]) // 2,\n",
    "            param1=param['param1'],\n",
    "            param2=param['param2'],\n",
    "            minRadius=int(min(cropped.shape[:2]) * param['minR']),\n",
    "            maxRadius=int(max(cropped.shape[:2]) * param['maxR'])\n",
    "        )\n",
    "        if circles is not None:\n",
    "            break\n",
    "\n",
    "    mask = np.zeros(cropped.shape[:2], dtype=np.uint8)\n",
    "\n",
    "    if circles is not None:\n",
    "        circles = np.uint16(np.around(circles))\n",
    "        # –ù–∞—ò–≥–æ–ª–µ–º–∞ –∫—Ä—É–∂–Ω–∏—Ü–∞\n",
    "        largest_circle = max(circles[0], key=lambda c: c[2])\n",
    "        center = (largest_circle[0], largest_circle[1])\n",
    "        radius = int(largest_circle[2] * 1.02)\n",
    "        cv2.circle(mask, center, radius, 255, -1)\n",
    "    else:\n",
    "        # Fallback: –µ–ª–∏–ø—Å–∞ –±–∞–∑–∏—Ä–∞–Ω–∞ –Ω–∞ bbox\n",
    "        ch, cw = cropped.shape[:2]\n",
    "        center = (cw // 2, ch // 2)\n",
    "        axes = (int(cw * 0.47), int(ch * 0.47))\n",
    "        cv2.ellipse(mask, center, axes, 0, 0, 360, 255, -1)\n",
    "\n",
    "    # –ú–æ—Ä—Ñ–æ–ª–æ—à–∫–∏ –æ–ø–µ—Ä–∞—Ü–∏–∏\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (9, 9))\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "    mask = cv2.GaussianBlur(mask, (11, 11), 0)\n",
    "\n",
    "    bgra = cv2.cvtColor(cropped, cv2.COLOR_BGR2BGRA)\n",
    "    bgra[:, :, 3] = mask\n",
    "\n",
    "    return bgra\n",
    "\n",
    "\n",
    "def remove_background_hybrid(image, bbox, padding=10, method='auto'):\n",
    "    \"\"\"\n",
    "    –•–∏–±—Ä–∏–¥–µ–Ω –º–µ—Ç–æ–¥ - –∫–æ–º–±–∏–Ω–∏—Ä–∞ –Ω–∞—ò–¥–æ–±—Ä–∏ —Ç–µ—Ö–Ω–∏–∫–∏\n",
    "\n",
    "    Args:\n",
    "        image: –í–ª–µ–∑–Ω–∞ —Å–ª–∏–∫–∞\n",
    "        bbox: Bounding box\n",
    "        padding: Padding\n",
    "        method: 'auto', 'grabcut', 'hough', 'edge', –∏–ª–∏ 'ensemble'\n",
    "\n",
    "    Returns:\n",
    "        BGRA —Å–ª–∏–∫–∞ —Å–æ transparent –ø–æ–∑–∞–¥–∏–Ω–∞\n",
    "    \"\"\"\n",
    "    if method == 'auto':\n",
    "        # –ê–≤—Ç–æ–º–∞—Ç—Å–∫–∏ –∏–∑–±–æ—Ä –±–∞–∑–∏—Ä–∞–Ω –Ω–∞ bbox –≥–æ–ª–µ–º–∏–Ω–∞\n",
    "        x1, y1, x2, y2 = map(int, bbox)\n",
    "        area = (x2 - x1) * (y2 - y1)\n",
    "\n",
    "        if area > 50000:  # –ì–æ–ª–µ–º–∞ –º–æ–Ω–µ—Ç–∞\n",
    "            method = 'grabcut'\n",
    "        elif area < 10000:  # –ú–∞–ª–∞ –º–æ–Ω–µ—Ç–∞\n",
    "            method = 'hough'\n",
    "        else:\n",
    "            method = 'edge'\n",
    "\n",
    "    if method == 'grabcut':\n",
    "        return remove_background_grabcut(image, bbox, padding)\n",
    "    elif method == 'hough':\n",
    "        return remove_background_hough_circles(image, bbox, padding)\n",
    "    elif method == 'edge':\n",
    "        return remove_background_edge_detection(image, bbox, padding)\n",
    "    elif method == 'ensemble':\n",
    "        # –ö–æ–º–±–∏–Ω–∏—Ä–∞—ò —Å–∏—Ç–µ —Ç—Ä–∏ –º–µ—Ç–æ–¥–∏\n",
    "        mask1 = remove_background_grabcut(image, bbox, padding)[:, :, 3]\n",
    "        mask2 = remove_background_hough_circles(image, bbox, padding)[:, :, 3]\n",
    "        mask3 = remove_background_edge_detection(image, bbox, padding)[:, :, 3]\n",
    "\n",
    "        # Weighted average\n",
    "        combined_mask = (mask1 * 0.4 + mask2 * 0.4 + mask3 * 0.2).astype(np.uint8)\n",
    "\n",
    "        x1, y1, x2, y2 = map(int, bbox)\n",
    "        h, w = image.shape[:2]\n",
    "        x1 = max(0, x1 - padding)\n",
    "        y1 = max(0, y1 - padding)\n",
    "        x2 = min(w, x2 + padding)\n",
    "        y2 = min(h, y2 + padding)\n",
    "        cropped = image[y1:y2, x1:x2].copy()\n",
    "\n",
    "        bgra = cv2.cvtColor(cropped, cv2.COLOR_BGR2BGRA)\n",
    "        bgra[:, :, 3] = combined_mask\n",
    "\n",
    "        return bgra\n",
    "    else:\n",
    "        # Default: Hough\n",
    "        return remove_background_hough_circles(image, bbox, padding)\n",
    "\n",
    "\n",
    "def enhance_coin_image(coin_bgra):\n",
    "    \"\"\"–ü–æ–¥–æ–±—Ä–∏ –≤–∏–∑—É–µ–ª–µ–Ω –∫–≤–∞–ª–∏—Ç–µ—Ç –Ω–∞ –º–æ–Ω–µ—Ç–∞—Ç–∞\"\"\"\n",
    "    # –ï–∫—Å—Ç—Ä–∞—Ö–∏—Ä–∞—ò –∫–∞–Ω–∞–ª–∏—Ç–µ\n",
    "    b, g, r, a = cv2.split(coin_bgra)\n",
    "\n",
    "    # CLAHE –∑–∞ –ø–æ–¥–æ–±–∞—Ä –∫–æ–Ω—Ç—Ä–∞—Å—Ç\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    b = clahe.apply(b)\n",
    "    g = clahe.apply(g)\n",
    "    r = clahe.apply(r)\n",
    "\n",
    "    # –°–ø–æ—ò–≥–∏ –Ω–∞–∑–∞–¥\n",
    "    enhanced = cv2.merge([b, g, r, a])\n",
    "\n",
    "    return enhanced\n",
    "\n",
    "\n",
    "# ==================== –¢–†–ï–ù–ò–†–ê–ä–ï ====================\n",
    "def train_coin_detector(config=CoinDetectorConfig):\n",
    "    \"\"\"–¢—Ä–µ–Ω–∏—Ä–∞—ò –º–æ–¥–µ–ª —Å–æ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–∞–Ω–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏\"\"\"\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"üèãÔ∏è  –ó–ê–ü–û–ß–ù–£–í–ê –¢–†–ï–ù–ò–†–ê–ä–ï –ù–ê –ú–û–î–ï–õ–û–¢\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"üìä –ú–æ–¥–µ–ª: {config.MODEL_SIZE}\")\n",
    "    print(f\"üìà –ï–ø–æ—Ö–∏: {config.EPOCHS}\")\n",
    "    print(f\"üì¶ Batch size: {config.BATCH_SIZE}\")\n",
    "    print(f\"üîç Image size: {config.IMAGE_SIZE}\")\n",
    "    print(f\"üéØ Optimizer: {config.OPTIMIZER}\")\n",
    "    print(\"=\" * 70 + \"\\n\")\n",
    "\n",
    "    # –í—á–∏—Ç–∞—ò –ø—Ä–µ—Ç—Ö–æ–¥–Ω–æ –æ–±—É—á–µ–Ω –º–æ–¥–µ–ª\n",
    "    model = YOLO(config.MODEL_SIZE)\n",
    "\n",
    "    # –¢—Ä–µ–Ω–∏—Ä–∞—ò\n",
    "    results = model.train(\n",
    "        data=DATA_YAML,\n",
    "        epochs=config.EPOCHS,\n",
    "        imgsz=config.IMAGE_SIZE,\n",
    "        batch=config.BATCH_SIZE,\n",
    "        patience=config.PATIENCE,\n",
    "        project=os.path.join(BASE_DIR, \"models\"),\n",
    "        name=config.MODEL_NAME,\n",
    "        device=0 if torch.cuda.is_available() else 'cpu',\n",
    "\n",
    "        # Optimizer\n",
    "        optimizer=config.OPTIMIZER,\n",
    "        lr0=config.LR0,\n",
    "        lrf=config.LRF,\n",
    "        momentum=config.MOMENTUM,\n",
    "        weight_decay=config.WEIGHT_DECAY,\n",
    "        warmup_epochs=config.WARMUP_EPOCHS,\n",
    "        warmup_momentum=0.8,\n",
    "        warmup_bias_lr=0.1,\n",
    "\n",
    "        # –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—ò–∞\n",
    "        hsv_h=config.HSV_H,\n",
    "        hsv_s=config.HSV_S,\n",
    "        hsv_v=config.HSV_V,\n",
    "        degrees=config.DEGREES,\n",
    "        translate=config.TRANSLATE,\n",
    "        scale=config.SCALE,\n",
    "        shear=config.SHEAR,\n",
    "        perspective=config.PERSPECTIVE,\n",
    "        flipud=config.FLIPUD,\n",
    "        fliplr=config.FLIPLR,\n",
    "        mosaic=config.MOSAIC,\n",
    "        mixup=config.MIXUP,\n",
    "        copy_paste=config.COPY_PASTE,\n",
    "\n",
    "        # Loss weights\n",
    "        box=config.BOX,\n",
    "        cls=config.CLS,\n",
    "        dfl=config.DFL,\n",
    "\n",
    "        # Output\n",
    "        save=True,\n",
    "        save_period=config.SAVE_PERIOD,\n",
    "        plots=True,\n",
    "        verbose=True,\n",
    "\n",
    "        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª–Ω–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ –∑–∞ –ø–æ–¥–æ–±—Ä–∏ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏\n",
    "        amp=True,  # Automatic Mixed Precision\n",
    "        fraction=1.0,  # –ö–æ—Ä–∏—Å—Ç–∏ —Ü–µ–ª –¥–∞—Ç–∞—Å–µ—Ç\n",
    "        close_mosaic=10,  # –ò—Å–∫–ª—É—á–∏ mosaic –ø–æ—Å–ª–µ–¥–Ω–∏—Ç–µ 10 –µ–ø–æ—Ö–∏\n",
    "    )\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"‚úÖ –¢–†–ï–ù–ò–†–ê–ä–ï–¢–û –ó–ê–í–†–®–ò –£–°–ü–ï–®–ù–û!\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"üìÅ –ú–æ–¥–µ–ª –∑–∞—á—É–≤–∞–Ω –≤–æ: {config.get_model_path()}\")\n",
    "    print(f\"üìä –ì—Ä–∞—Ñ–∏–∫–æ–Ω–∏ –¥–æ—Å—Ç–∞–ø–Ω–∏ –≤–æ: {os.path.join(BASE_DIR, 'models', config.MODEL_NAME)}\")\n",
    "    print(\"=\" * 70 + \"\\n\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# ==================== –í–ê–õ–ò–î–ê–¶–ò–à–ê –ò –¢–ï–°–¢–ò–†–ê–ä–ï ====================\n",
    "def validate_model(model, verbose=True):\n",
    "    \"\"\"–î–µ—Ç–∞–ª–Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏—ò–∞ –Ω–∞ –º–æ–¥–µ–ª–æ—Ç\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"üìä –í–ê–õ–ò–î–ê–¶–ò–à–ê –ù–ê –ú–û–î–ï–õ–û–¢\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    metrics = model.val()\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"\\n{'–ú–µ—Ç—Ä–∏–∫–∞':<20} {'–í—Ä–µ–¥–Ω–æ—Å—Ç':>10}\")\n",
    "        print(\"-\" * 32)\n",
    "        print(f\"{'mAP50':<20} {metrics.box.map50:>10.4f}\")\n",
    "        print(f\"{'mAP50-95':<20} {metrics.box.map:>10.4f}\")\n",
    "        print(f\"{'Precision':<20} {metrics.box.mp:>10.4f}\")\n",
    "        print(f\"{'Recall':<20} {metrics.box.mr:>10.4f}\")\n",
    "        print(f\"{'F1-Score':<20} {2 * (metrics.box.mp * metrics.box.mr) / (metrics.box.mp + metrics.box.mr + 1e-6):>10.4f}\")\n",
    "        print(\"-\" * 32)\n",
    "\n",
    "        # Per-class –º–µ—Ç—Ä–∏–∫–∏\n",
    "        if hasattr(metrics.box, 'ap_class_index') and len(metrics.box.ap_class_index) > 0:\n",
    "            print(f\"\\n{'–ö–ª–∞—Å–∞':<15} {'AP50':>10} {'Precision':>10} {'Recall':>10}\")\n",
    "            print(\"-\" * 47)\n",
    "            for i, cls_idx in enumerate(metrics.box.ap_class_index):\n",
    "                class_name = model.names[int(cls_idx)]\n",
    "                print(f\"{class_name:<15} {metrics.box.ap50[i]:>10.4f} {metrics.box.p[i]:>10.4f} {metrics.box.r[i]:>10.4f}\")\n",
    "\n",
    "    print(\"=\" * 70 + \"\\n\")\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def test_detection(model, image_path, save_output=True, config=CoinDetectorConfig):\n",
    "    \"\"\"\n",
    "    –¢–µ—Å—Ç–∏—Ä–∞—ò –¥–µ—Ç–µ–∫—Ü–∏—ò–∞ —Å–æ –∑–∞—á—É–≤—É–≤–∞—ö–µ –Ω–∞ –ø—Ä–æ—Ü–µ—Å–∏—Ä–∞–Ω–∏ –º–æ–Ω–µ—Ç–∏\n",
    "\n",
    "    Args:\n",
    "        model: YOLO –º–æ–¥–µ–ª\n",
    "        image_path: –ü–∞—Ç–µ–∫–∞ –¥–æ —Å–ª–∏–∫–∞\n",
    "        save_output: –î–∞–ª–∏ –¥–∞ —Å–µ –∑–∞—á—É–≤–∞–∞—Ç —Ä–µ–∑—É–ª—Ç–∞—Ç–∏—Ç–µ\n",
    "        config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—ò–∞\n",
    "    \"\"\"\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"‚ùå –°–ª–∏–∫–∞—Ç–∞ –Ω–µ –ø–æ—Å—Ç–æ–∏: {image_path}\")\n",
    "        return None\n",
    "\n",
    "    print(f\"\\nüîç –î–µ—Ç–µ–∫—Ç–∏—Ä–∞—ö–µ –º–æ–Ω–µ—Ç–∏ –≤–æ: {os.path.basename(image_path)}\")\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    if image is None:\n",
    "        print(f\"‚ùå –ì—Ä–µ—à–∫–∞ –ø—Ä–∏ –≤—á–∏—Ç—É–≤–∞—ö–µ –Ω–∞ —Å–ª–∏–∫–∞—Ç–∞\")\n",
    "        return None\n",
    "\n",
    "    # –î–µ—Ç–µ–∫—Ü–∏—ò–∞\n",
    "    results = model.predict(\n",
    "        image,\n",
    "        conf=config.CONF_THRESHOLD,\n",
    "        iou=config.IOU_THRESHOLD,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    detected_coins = []\n",
    "\n",
    "    for result in results:\n",
    "        boxes = result.boxes\n",
    "\n",
    "        if len(boxes) == 0:\n",
    "            print(\"   ‚ö†Ô∏è  –ù–µ —Å–µ –¥–µ—Ç–µ–∫—Ç–∏—Ä–∞–Ω–∏ –º–æ–Ω–µ—Ç–∏\")\n",
    "            return []\n",
    "\n",
    "        print(f\"\\n   ‚úÖ –ü—Ä–æ–Ω–∞—ò–¥–µ–Ω–∏ {len(boxes)} –º–æ–Ω–µ—Ç–∏:\")\n",
    "        print(f\"   {'#':<4} {'–ö–ª–∞—Å–∞':<12} {'Confidence':<12} {'Bbox'}\")\n",
    "        print(\"   \" + \"-\" * 60)\n",
    "\n",
    "        for i, box in enumerate(boxes):\n",
    "            bbox = box.xyxy[0].cpu().numpy()\n",
    "            conf = float(box.conf[0].cpu().numpy())\n",
    "            cls = int(box.cls[0].cpu().numpy())\n",
    "            class_name = model.names[cls]\n",
    "\n",
    "            print(f\"   {i+1:<4} {class_name:<12} {conf:>6.2%}      {bbox.astype(int).tolist()}\")\n",
    "\n",
    "            # –û—Ç—Å—Ç—Ä–∞–Ω–∏ –ø–æ–∑–∞–¥–∏–Ω–∞ - –∏–∑–±–µ—Ä–∏ –º–µ—Ç–æ–¥\n",
    "            # –û–ø—Ü–∏–∏: 'auto', 'grabcut', 'hough', 'edge', 'ensemble'\n",
    "            coin_bgra = remove_background_hybrid(image, bbox, padding=10, method='auto')\n",
    "            coin_enhanced = enhance_coin_image(coin_bgra)\n",
    "\n",
    "            detected_coins.append({\n",
    "                'class': class_name,\n",
    "                'confidence': conf,\n",
    "                'bbox': bbox,\n",
    "                'image': coin_bgra,\n",
    "                'image_enhanced': coin_enhanced\n",
    "            })\n",
    "\n",
    "            # –ó–∞—á—É–≤–∞—ò\n",
    "            if save_output:\n",
    "                output_dir = os.path.join(BASE_DIR, \"output\", \"detected_coins\")\n",
    "                os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "                # –û—Ä–∏–≥–∏–Ω–∞–ª\n",
    "                orig_path = os.path.join(output_dir, f\"{i+1}_{class_name}_{conf:.3f}.png\")\n",
    "                cv2.imwrite(orig_path, coin_bgra)\n",
    "\n",
    "                # Enhanced\n",
    "                enh_path = os.path.join(output_dir, f\"{i+1}_{class_name}_{conf:.3f}_enhanced.png\")\n",
    "                cv2.imwrite(enh_path, coin_enhanced)\n",
    "\n",
    "    if save_output and len(detected_coins) > 0:\n",
    "        print(f\"\\n   üíæ –ó–∞—á—É–≤–∞–Ω–æ {len(detected_coins) * 2} —Å–ª–∏–∫–∏ –≤–æ: {output_dir}\")\n",
    "\n",
    "    return detected_coins\n",
    "\n",
    "\n",
    "# ==================== –ì–õ–ê–í–ù–ê –õ–û–ì–ò–ö–ê ====================\n",
    "def main():\n",
    "    \"\"\"–ì–ª–∞–≤–Ω–∞ —Ñ—É–Ω–∫—Ü–∏—ò–∞\"\"\"\n",
    "    config = CoinDetectorConfig\n",
    "\n",
    "    if config.TRAIN_NEW:\n",
    "        # –¢—Ä–µ–Ω–∏—Ä–∞—ò –Ω–æ–≤ –º–æ–¥–µ–ª\n",
    "        model = train_coin_detector(config)\n",
    "        model_path = config.get_model_path()\n",
    "    else:\n",
    "        # –í—á–∏—Ç–∞—ò –ø–æ—Å—Ç–æ–µ—á–∫–∏\n",
    "        model_path = config.get_model_path()\n",
    "\n",
    "        if not os.path.exists(model_path):\n",
    "            print(f\"\\n‚ùå –ú–æ–¥–µ–ª–æ—Ç –Ω–µ –ø–æ—Å—Ç–æ–∏: {model_path}\")\n",
    "            print(\"üí° –ü—Ä–æ–º–µ–Ω–∏ CoinDetectorConfig.TRAIN_NEW = True –∑–∞ —Ç—Ä–µ–Ω–∏—Ä–∞—ö–µ\\n\")\n",
    "            return None\n",
    "\n",
    "        print(f\"\\nüìÇ –í—á–∏—Ç—É–≤–∞—ö–µ –º–æ–¥–µ–ª –æ–¥: {model_path}\")\n",
    "        model = YOLO(model_path)\n",
    "        print(\"‚úÖ –ú–æ–¥–µ–ª–æ—Ç –µ —É—Å–ø–µ—à–Ω–æ –≤—á–∏—Ç–∞–Ω!\\n\")\n",
    "\n",
    "    # –ü—Ä–∏–∫–∞–∂–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏\n",
    "    print(\"üìã –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∑–∞ –º–æ–¥–µ–ª–æ—Ç:\")\n",
    "    print(f\"   –ë—Ä–æ—ò –Ω–∞ –∫–ª–∞—Å–∏: {len(model.names)}\")\n",
    "    print(f\"   –ö–ª–∞—Å–∏: {list(model.names.values())}\")\n",
    "\n",
    "    # –í–∞–ª–∏–¥–∏—Ä–∞—ò\n",
    "    if os.path.exists(DATA_YAML):\n",
    "        validate_model(model)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"üéØ –ú–û–î–ï–õ–û–¢ –ï –ü–û–î–ì–û–¢–í–ï–ù –ó–ê –£–ü–û–¢–†–ï–ë–ê!\")\n",
    "    print(\"=\" * 70)\n",
    "    print(\"\\nüí° –ü—Ä–∏–º–µ—Ä–∏ –∑–∞ —É–ø–æ—Ç—Ä–µ–±–∞:\")\n",
    "    print(\"   # –¢–µ—Å—Ç–∏—Ä–∞—ò –¥–µ—Ç–µ–∫—Ü–∏—ò–∞\")\n",
    "    print(\"   test_detection(model, 'path/to/image.jpg')\")\n",
    "    print(\"\\n   # –í–∞–ª–∏–¥–∏—Ä–∞—ò –º–æ–¥–µ–ª\")\n",
    "    print(\"   validate_model(model)\")\n",
    "    print(\"\\n   # –î–∏—Ä–µ–∫—Ç–Ω–∞ –ø—Ä–µ–¥–∏–∫—Ü–∏—ò–∞\")\n",
    "    print(\"   results = model.predict('path/to/image.jpg', conf=0.35)\")\n",
    "    print(\"=\" * 70 + \"\\n\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# –°—Ç–∞—Ä—Ç—É–≤–∞—ò\n",
    "if __name__ == \"__main__\":\n",
    "    model = main()"
   ],
   "id": "466e1955fca9d832",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ü™ô –ú–ê–ö–ï–î–û–ù–°–ö–ò –î–ï–¢–ï–ö–¢–û–† –ó–ê –ú–û–ù–ï–¢–ò - –û–ø—Ç–∏–º–∏–∑–∏—Ä–∞–Ω–∞ –≤–µ—Ä–∑–∏—ò–∞\n",
      "======================================================================\n",
      "üìÅ BASE_DIR: C:\\Users\\User5549\\Desktop\\Marija\\MKD-Currency-Detector\\CurrencyDetectorApp\\yolov8_training\n",
      "üìÑ DATA_YAML: C:\\Users\\User5549\\Desktop\\Marija\\MKD-Currency-Detector\\CurrencyDetectorApp\\yolov8_training\\datasets\\coin\\data.yaml\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "üèãÔ∏è  –ó–ê–ü–û–ß–ù–£–í–ê –¢–†–ï–ù–ò–†–ê–ä–ï –ù–ê –ú–û–î–ï–õ–û–¢\n",
      "======================================================================\n",
      "üìä –ú–æ–¥–µ–ª: yolov8m.pt\n",
      "üìà –ï–ø–æ—Ö–∏: 200\n",
      "üì¶ Batch size: 8\n",
      "üîç Image size: 640\n",
      "üéØ Optimizer: AdamW\n",
      "======================================================================\n",
      "\n",
      "\u001B[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8m.pt to 'yolov8m.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 49.7MB 26.9MB/s 1.8s1.8s<0.1s0s\n",
      "New https://pypi.org/project/ultralytics/8.4.6 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.241  Python-3.12.10 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 5070, 12227MiB)\n",
      "\u001B[34m\u001B[1mengine\\trainer: \u001B[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=1.0, compile=False, conf=None, copy_paste=0.3, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=C:\\Users\\User5549\\Desktop\\Marija\\MKD-Currency-Detector\\CurrencyDetectorApp\\yolov8_training\\datasets\\coin\\data.yaml, degrees=45, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=200, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.5, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.02, hsv_s=0.8, hsv_v=0.5, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0005, lrf=0.001, mask_ratio=4, max_det=300, mixup=0.15, mode=train, model=yolov8m.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=coin_detector_mk_optimized, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=50, perspective=0.001, plots=True, pose=12.0, pretrained=True, profile=False, project=C:\\Users\\User5549\\Desktop\\Marija\\MKD-Currency-Detector\\CurrencyDetectorApp\\yolov8_training\\models, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\User5549\\Desktop\\Marija\\MKD-Currency-Detector\\CurrencyDetectorApp\\yolov8_training\\models\\coin_detector_mk_optimized, save_frames=False, save_json=False, save_period=20, save_txt=False, scale=0.7, seed=0, shear=5.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.2, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=5.0, warmup_momentum=0.8, weight_decay=0.001, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3778591  ultralytics.nn.modules.head.Detect           [5, [192, 384, 576]]          \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User5549\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\cuda\\__init__.py:235: UserWarning: \n",
      "NVIDIA GeForce RTX 5070 with CUDA capability sm_120 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_50 sm_60 sm_61 sm_70 sm_75 sm_80 sm_86 sm_90.\n",
      "If you want to use the NVIDIA GeForce RTX 5070 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model summary: 169 layers, 25,859,215 parameters, 25,859,199 gradients, 79.1 GFLOPs\n",
      "\n",
      "Transferred 469/475 items from pretrained weights\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: no kernel image is available for execution on the device\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mRuntimeError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 588\u001B[39m\n\u001B[32m    586\u001B[39m \u001B[38;5;66;03m# –°—Ç–∞—Ä—Ç—É–≤–∞—ò\u001B[39;00m\n\u001B[32m    587\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[34m__name__\u001B[39m == \u001B[33m\"\u001B[39m\u001B[33m__main__\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m588\u001B[39m     model = \u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 547\u001B[39m, in \u001B[36mmain\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m    543\u001B[39m config = CoinDetectorConfig\n\u001B[32m    545\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m config.TRAIN_NEW:\n\u001B[32m    546\u001B[39m     \u001B[38;5;66;03m# –¢—Ä–µ–Ω–∏—Ä–∞—ò –Ω–æ–≤ –º–æ–¥–µ–ª\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m547\u001B[39m     model = \u001B[43mtrain_coin_detector\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    548\u001B[39m     model_path = config.get_model_path()\n\u001B[32m    549\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    550\u001B[39m     \u001B[38;5;66;03m# –í—á–∏—Ç–∞—ò –ø–æ—Å—Ç–æ–µ—á–∫–∏\u001B[39;00m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 365\u001B[39m, in \u001B[36mtrain_coin_detector\u001B[39m\u001B[34m(config)\u001B[39m\n\u001B[32m    362\u001B[39m model = YOLO(config.MODEL_SIZE)\n\u001B[32m    364\u001B[39m \u001B[38;5;66;03m# –¢—Ä–µ–Ω–∏—Ä–∞—ò\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m365\u001B[39m results = \u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    366\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m=\u001B[49m\u001B[43mDATA_YAML\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    367\u001B[39m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mEPOCHS\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    368\u001B[39m \u001B[43m    \u001B[49m\u001B[43mimgsz\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mIMAGE_SIZE\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    369\u001B[39m \u001B[43m    \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mBATCH_SIZE\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    370\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpatience\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mPATIENCE\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    371\u001B[39m \u001B[43m    \u001B[49m\u001B[43mproject\u001B[49m\u001B[43m=\u001B[49m\u001B[43mos\u001B[49m\u001B[43m.\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m.\u001B[49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mBASE_DIR\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmodels\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    372\u001B[39m \u001B[43m    \u001B[49m\u001B[43mname\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mMODEL_NAME\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    373\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcuda\u001B[49m\u001B[43m.\u001B[49m\u001B[43mis_available\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mcpu\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    374\u001B[39m \n\u001B[32m    375\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# Optimizer\u001B[39;49;00m\n\u001B[32m    376\u001B[39m \u001B[43m    \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mOPTIMIZER\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    377\u001B[39m \u001B[43m    \u001B[49m\u001B[43mlr0\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mLR0\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    378\u001B[39m \u001B[43m    \u001B[49m\u001B[43mlrf\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mLRF\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    379\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmomentum\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mMOMENTUM\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    380\u001B[39m \u001B[43m    \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mWEIGHT_DECAY\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    381\u001B[39m \u001B[43m    \u001B[49m\u001B[43mwarmup_epochs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mWARMUP_EPOCHS\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    382\u001B[39m \u001B[43m    \u001B[49m\u001B[43mwarmup_momentum\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m0.8\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    383\u001B[39m \u001B[43m    \u001B[49m\u001B[43mwarmup_bias_lr\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m0.1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    384\u001B[39m \n\u001B[32m    385\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—ò–∞\u001B[39;49;00m\n\u001B[32m    386\u001B[39m \u001B[43m    \u001B[49m\u001B[43mhsv_h\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mHSV_H\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    387\u001B[39m \u001B[43m    \u001B[49m\u001B[43mhsv_s\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mHSV_S\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    388\u001B[39m \u001B[43m    \u001B[49m\u001B[43mhsv_v\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mHSV_V\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    389\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdegrees\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mDEGREES\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    390\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtranslate\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mTRANSLATE\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    391\u001B[39m \u001B[43m    \u001B[49m\u001B[43mscale\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mSCALE\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    392\u001B[39m \u001B[43m    \u001B[49m\u001B[43mshear\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mSHEAR\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    393\u001B[39m \u001B[43m    \u001B[49m\u001B[43mperspective\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mPERSPECTIVE\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    394\u001B[39m \u001B[43m    \u001B[49m\u001B[43mflipud\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mFLIPUD\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    395\u001B[39m \u001B[43m    \u001B[49m\u001B[43mfliplr\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mFLIPLR\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    396\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmosaic\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mMOSAIC\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    397\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmixup\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mMIXUP\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    398\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcopy_paste\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mCOPY_PASTE\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    399\u001B[39m \n\u001B[32m    400\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# Loss weights\u001B[39;49;00m\n\u001B[32m    401\u001B[39m \u001B[43m    \u001B[49m\u001B[43mbox\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mBOX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    402\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mCLS\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    403\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdfl\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mDFL\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    404\u001B[39m \n\u001B[32m    405\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# Output\u001B[39;49;00m\n\u001B[32m    406\u001B[39m \u001B[43m    \u001B[49m\u001B[43msave\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    407\u001B[39m \u001B[43m    \u001B[49m\u001B[43msave_period\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mSAVE_PERIOD\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    408\u001B[39m \u001B[43m    \u001B[49m\u001B[43mplots\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    409\u001B[39m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    410\u001B[39m \n\u001B[32m    411\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª–Ω–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ –∑–∞ –ø–æ–¥–æ–±—Ä–∏ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏\u001B[39;49;00m\n\u001B[32m    412\u001B[39m \u001B[43m    \u001B[49m\u001B[43mamp\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Automatic Mixed Precision\u001B[39;49;00m\n\u001B[32m    413\u001B[39m \u001B[43m    \u001B[49m\u001B[43mfraction\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m1.0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# –ö–æ—Ä–∏—Å—Ç–∏ —Ü–µ–ª –¥–∞—Ç–∞—Å–µ—Ç\u001B[39;49;00m\n\u001B[32m    414\u001B[39m \u001B[43m    \u001B[49m\u001B[43mclose_mosaic\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# –ò—Å–∫–ª—É—á–∏ mosaic –ø–æ—Å–ª–µ–¥–Ω–∏—Ç–µ 10 –µ–ø–æ—Ö–∏\u001B[39;49;00m\n\u001B[32m    415\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    417\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m + \u001B[33m\"\u001B[39m\u001B[33m=\u001B[39m\u001B[33m\"\u001B[39m * \u001B[32m70\u001B[39m)\n\u001B[32m    418\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33m‚úÖ –¢–†–ï–ù–ò–†–ê–ä–ï–¢–û –ó–ê–í–†–®–ò –£–°–ü–ï–®–ù–û!\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\model.py:773\u001B[39m, in \u001B[36mModel.train\u001B[39m\u001B[34m(self, trainer, **kwargs)\u001B[39m\n\u001B[32m    770\u001B[39m     \u001B[38;5;28mself\u001B[39m.trainer.model = \u001B[38;5;28mself\u001B[39m.trainer.get_model(weights=\u001B[38;5;28mself\u001B[39m.model \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.ckpt \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, cfg=\u001B[38;5;28mself\u001B[39m.model.yaml)\n\u001B[32m    771\u001B[39m     \u001B[38;5;28mself\u001B[39m.model = \u001B[38;5;28mself\u001B[39m.trainer.model\n\u001B[32m--> \u001B[39m\u001B[32m773\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtrainer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    774\u001B[39m \u001B[38;5;66;03m# Update model and cfg after training\u001B[39;00m\n\u001B[32m    775\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m RANK \u001B[38;5;129;01min\u001B[39;00m {-\u001B[32m1\u001B[39m, \u001B[32m0\u001B[39m}:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:243\u001B[39m, in \u001B[36mBaseTrainer.train\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    240\u001B[39m         ddp_cleanup(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28mstr\u001B[39m(file))\n\u001B[32m    242\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m243\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_do_train\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:364\u001B[39m, in \u001B[36mBaseTrainer._do_train\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    362\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.world_size > \u001B[32m1\u001B[39m:\n\u001B[32m    363\u001B[39m     \u001B[38;5;28mself\u001B[39m._setup_ddp()\n\u001B[32m--> \u001B[39m\u001B[32m364\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_setup_train\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    366\u001B[39m nb = \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m.train_loader)  \u001B[38;5;66;03m# number of batches\u001B[39;00m\n\u001B[32m    367\u001B[39m nw = \u001B[38;5;28mmax\u001B[39m(\u001B[38;5;28mround\u001B[39m(\u001B[38;5;28mself\u001B[39m.args.warmup_epochs * nb), \u001B[32m100\u001B[39m) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.args.warmup_epochs > \u001B[32m0\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m -\u001B[32m1\u001B[39m  \u001B[38;5;66;03m# warmup iterations\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:268\u001B[39m, in \u001B[36mBaseTrainer._setup_train\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    266\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Build dataloaders and optimizer on correct rank process.\"\"\"\u001B[39;00m\n\u001B[32m    267\u001B[39m ckpt = \u001B[38;5;28mself\u001B[39m.setup_model()\n\u001B[32m--> \u001B[39m\u001B[32m268\u001B[39m \u001B[38;5;28mself\u001B[39m.model = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    269\u001B[39m \u001B[38;5;28mself\u001B[39m.set_model_attributes()\n\u001B[32m    271\u001B[39m \u001B[38;5;66;03m# Compile model\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1340\u001B[39m, in \u001B[36mModule.to\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1337\u001B[39m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1338\u001B[39m             \u001B[38;5;28;01mraise\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1340\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:281\u001B[39m, in \u001B[36mBaseModel._apply\u001B[39m\u001B[34m(self, fn)\u001B[39m\n\u001B[32m    272\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_apply\u001B[39m(\u001B[38;5;28mself\u001B[39m, fn):\n\u001B[32m    273\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Apply a function to all tensors in the model that are not parameters or registered buffers.\u001B[39;00m\n\u001B[32m    274\u001B[39m \n\u001B[32m    275\u001B[39m \u001B[33;03m    Args:\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    279\u001B[39m \u001B[33;03m        (BaseModel): An updated BaseModel object.\u001B[39;00m\n\u001B[32m    280\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m281\u001B[39m     \u001B[38;5;28mself\u001B[39m = \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    282\u001B[39m     m = \u001B[38;5;28mself\u001B[39m.model[-\u001B[32m1\u001B[39m]  \u001B[38;5;66;03m# Detect()\u001B[39;00m\n\u001B[32m    283\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\n\u001B[32m    284\u001B[39m         m, Detect\n\u001B[32m    285\u001B[39m     ):  \u001B[38;5;66;03m# includes all Detect subclasses like Segment, Pose, OBB, WorldDetect, YOLOEDetect, YOLOESegment\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:900\u001B[39m, in \u001B[36mModule._apply\u001B[39m\u001B[34m(self, fn, recurse)\u001B[39m\n\u001B[32m    898\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m recurse:\n\u001B[32m    899\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.children():\n\u001B[32m--> \u001B[39m\u001B[32m900\u001B[39m         \u001B[43mmodule\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    902\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[32m    903\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[32m    904\u001B[39m         \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[32m    905\u001B[39m         \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    910\u001B[39m         \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[32m    911\u001B[39m         \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:900\u001B[39m, in \u001B[36mModule._apply\u001B[39m\u001B[34m(self, fn, recurse)\u001B[39m\n\u001B[32m    898\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m recurse:\n\u001B[32m    899\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.children():\n\u001B[32m--> \u001B[39m\u001B[32m900\u001B[39m         \u001B[43mmodule\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    902\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[32m    903\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[32m    904\u001B[39m         \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[32m    905\u001B[39m         \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    910\u001B[39m         \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[32m    911\u001B[39m         \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:900\u001B[39m, in \u001B[36mModule._apply\u001B[39m\u001B[34m(self, fn, recurse)\u001B[39m\n\u001B[32m    898\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m recurse:\n\u001B[32m    899\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.children():\n\u001B[32m--> \u001B[39m\u001B[32m900\u001B[39m         \u001B[43mmodule\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    902\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[32m    903\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[32m    904\u001B[39m         \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[32m    905\u001B[39m         \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    910\u001B[39m         \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[32m    911\u001B[39m         \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:927\u001B[39m, in \u001B[36mModule._apply\u001B[39m\u001B[34m(self, fn, recurse)\u001B[39m\n\u001B[32m    923\u001B[39m \u001B[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001B[39;00m\n\u001B[32m    924\u001B[39m \u001B[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001B[39;00m\n\u001B[32m    925\u001B[39m \u001B[38;5;66;03m# `with torch.no_grad():`\u001B[39;00m\n\u001B[32m    926\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m torch.no_grad():\n\u001B[32m--> \u001B[39m\u001B[32m927\u001B[39m     param_applied = \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparam\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    928\u001B[39m p_should_use_set_data = compute_should_use_set_data(param, param_applied)\n\u001B[32m    930\u001B[39m \u001B[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1326\u001B[39m, in \u001B[36mModule.to.<locals>.convert\u001B[39m\u001B[34m(t)\u001B[39m\n\u001B[32m   1319\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m convert_to_format \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m t.dim() \u001B[38;5;129;01min\u001B[39;00m (\u001B[32m4\u001B[39m, \u001B[32m5\u001B[39m):\n\u001B[32m   1320\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m t.to(\n\u001B[32m   1321\u001B[39m             device,\n\u001B[32m   1322\u001B[39m             dtype \u001B[38;5;28;01mif\u001B[39;00m t.is_floating_point() \u001B[38;5;129;01mor\u001B[39;00m t.is_complex() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m   1323\u001B[39m             non_blocking,\n\u001B[32m   1324\u001B[39m             memory_format=convert_to_format,\n\u001B[32m   1325\u001B[39m         )\n\u001B[32m-> \u001B[39m\u001B[32m1326\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mt\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1327\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1328\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[43m.\u001B[49m\u001B[43mis_floating_point\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[43m.\u001B[49m\u001B[43mis_complex\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m   1329\u001B[39m \u001B[43m        \u001B[49m\u001B[43mnon_blocking\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1330\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1331\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m   1332\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(e) == \u001B[33m\"\u001B[39m\u001B[33mCannot copy out of meta tensor; no data!\u001B[39m\u001B[33m\"\u001B[39m:\n",
      "\u001B[31mRuntimeError\u001B[39m: CUDA error: no kernel image is available for execution on the device\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e8984a26a3c1c1f7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
